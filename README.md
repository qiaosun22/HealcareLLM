# HealcareLLM

## 心理学大模型

| **模型**            | **作者**                                          | **发表**                                                     | **定位**                                                 | **预训练**                                                   | **微调**                      | **数据集**                                                   | **规模/B**           | **评测指标** | **Comments**                                                 |
| ------------------- | ------------------------------------------------- | ------------------------------------------------------------ | -------------------------------------------------------- | ------------------------------------------------------------ | ----------------------------- | ------------------------------------------------------------ | -------------------- | ------------ | ------------------------------------------------------------ |
| MindChat 漫谈23/6/6 | X-D-Lab华东理工                                   | github.com/X-D-Lab/MindChat                                  | 中文/心理抚慰                                            | Baichuan/InternLM/[Qwen-7B](https://github.com/QwenLM/Qwen-7B) | 多轮对话微调                  | 【闭源】**100w:** 自动化流程构造/多轮心理对话【example】https://github.com/X-D-Lab/MindChat/blob/main/data/dataset_example.json | 0.5/1.8/4/7/14       | 无           | -                                                            |
| SoulChat 灵心23/6/6 | 华南理工                                          | Findings of EMNLP 2023https://github.com/scutcyr/SoulChat    | 中文/心理健康/共情与倾听                                 | [ChatGLM-6B](https://huggingface.co/THUDM/chatglm-6b)        | 全量参数的指令微调            | 15w 单轮长文本心理咨询指令与答案100w轮次 ChatGPT与GPT4生成的 多轮回答数据单轮与多轮混合的共情对话数据集 | 6                    | 无           | -                                                            |
| EMOLLM24/1/25       | [SmartFlowAI](https://github.com/SmartFlowAI)南开 | 上海人工智能实验室2024浦源大模型系列挑战赛春季赛*创新创意奖* | 中文/理解用户-支持用户-帮助用户心理健康辅导链路/角色扮演 | InternLM2/Qwen/DeepSeek MoE/Mixtral/Baichuan/ChatGLM3        | QLORA/LORA/全量微调via xtuner | 1w 单轮和多轮对话数据 gen by 文心一言、通义千问、讯飞星火和智谱GLM | 5/6/7/8/13/16/20/8x7 | 无           | 有详细的[数据生成](http://github.com/SmartFlowAI/EmoLLM/blob/main/generate_data/tutorial.md)和模型微调文档 |
|                     |                                                   |                                                              |                                                          |                                                              |                               |                                                              |                      |              |                                                              |

## 心理学数据集

| **名称**                                   | **作者**                                    | **发表**            | **定位**                                                     | **形式**   | **规模** | **开源方式** |
| ------------------------------------------ | ------------------------------------------- | ------------------- | ------------------------------------------------------------ | ---------- | -------- | ------------ |
| [PsyQA](https://github.com/thu-coai/PsyQA) | [thu-coai](https://github.com/thu-coai)清华 | Finding of ACL 2021 | 一个中文心理健康支持问答数据集，提供了丰富的援助策略标注。可用于生成富有援助策略的长咨询文本。 | QA多轮对话 | ～7w     | 邮件申请获取 |
|                                            |                                             |                     |                                                              |            |          |              |
|                                            |                                             |                     |                                                              |            |          |              |
